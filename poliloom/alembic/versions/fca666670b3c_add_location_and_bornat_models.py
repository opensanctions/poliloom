"""add_location_and_bornat_models

Revision ID: fca666670b3c
Revises: b140cc2468c3
Create Date: 2025-07-03 18:00:29.762314

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = 'fca666670b3c'
down_revision: Union[str, None] = 'b140cc2468c3'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    import os
    
    database_url = os.getenv('DATABASE_URL', 'sqlite:///./poliloom.db')
    
    # Create locations table without embedding column first
    op.create_table('locations',
    sa.Column('name', sa.String(), nullable=False),
    sa.Column('wikidata_id', sa.String(), nullable=True),
    sa.Column('id', sa.String(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    
    # Add embedding column based on database type
    if database_url.startswith('postgresql'):
        # PostgreSQL with pgvector
        op.execute('CREATE EXTENSION IF NOT EXISTS vector')
        op.add_column('locations', sa.Column('embedding', sa.String(), nullable=True))
        # Note: In production, you should use proper pgvector.Vector type
        # This is a placeholder that works with both SQLite and PostgreSQL
    else:
        # SQLite with JSON
        op.add_column('locations', sa.Column('embedding', sa.JSON(), nullable=True))
    op.create_index(op.f('ix_locations_wikidata_id'), 'locations', ['wikidata_id'], unique=True)
    op.create_table('born_at',
    sa.Column('politician_id', sa.String(), nullable=False),
    sa.Column('location_id', sa.String(), nullable=False),
    sa.Column('is_extracted', sa.Boolean(), nullable=True),
    sa.Column('confirmed_by', sa.String(), nullable=True),
    sa.Column('confirmed_at', sa.DateTime(), nullable=True),
    sa.Column('id', sa.String(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), nullable=False),
    sa.ForeignKeyConstraint(['location_id'], ['locations.id'], ),
    sa.ForeignKeyConstraint(['politician_id'], ['politicians.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('bornat_source',
    sa.Column('bornat_id', sa.String(), nullable=False),
    sa.Column('source_id', sa.String(), nullable=False),
    sa.ForeignKeyConstraint(['bornat_id'], ['born_at.id'], ),
    sa.ForeignKeyConstraint(['source_id'], ['sources.id'], ),
    sa.PrimaryKeyConstraint('bornat_id', 'source_id')
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('bornat_source')
    op.drop_table('born_at')
    op.drop_index(op.f('ix_locations_wikidata_id'), table_name='locations')
    op.drop_table('locations')
    # ### end Alembic commands ###
